{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f1a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9700ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = \"4.txt\"\n",
    "vector_dim    = 100\n",
    "window_size   = 2\n",
    "min_count     = 1\n",
    "epochs        = 5\n",
    "batch_size    = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc929f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 533, Total tokens: 1546\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text.split()\n",
    "\n",
    "with open(document_path, encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "tokens = tokenize(text)\n",
    "freqs = Counter(tokens)\n",
    "vocab = [w for w, c in freqs.items() if c >= min_count]\n",
    "idx2word = ['<unk>'] + sorted(vocab)\n",
    "word2idx = {w: i for i, w in enumerate(idx2word)}\n",
    "V = len(idx2word)\n",
    "print(f\"Vocab size: {V}, Total tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba1c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_contexts, cbow_targets = [], []\n",
    "for i, w in enumerate(tokens):\n",
    "    context = []\n",
    "    for j in range(i-window_size, i+window_size+1):\n",
    "        if j != i and 0 <= j < len(tokens):\n",
    "            context.append(word2idx.get(tokens[j], 0))\n",
    "    if len(context) == 2 * window_size:\n",
    "        cbow_contexts.append(context)\n",
    "        cbow_targets.append(word2idx.get(w, 0))\n",
    "cbow_contexts = np.array(cbow_contexts, dtype=np.int32)\n",
    "cbow_targets  = np.array(cbow_targets,  dtype=np.int32)\n",
    "\n",
    "sg_centers, sg_contexts = [], []\n",
    "for i, w in enumerate(tokens):\n",
    "    center = word2idx.get(w, 0)\n",
    "    for j in range(i-window_size, i+window_size+1):\n",
    "        if j != i and 0 <= j < len(tokens):\n",
    "            sg_centers.append(center)\n",
    "            sg_contexts.append(word2idx.get(tokens[j], 0))\n",
    "sg_centers = np.array(sg_centers, dtype=np.int32)\n",
    "sg_contexts = np.array(sg_contexts, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88caceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW examples: (1542, 4) Skip‑Gram examples: (6178,)\n"
     ]
    }
   ],
   "source": [
    "cbow_ds = (tf.data.Dataset\n",
    "           .from_tensor_slices((cbow_contexts, cbow_targets))\n",
    "           .shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "sg_ds   = (tf.data.Dataset\n",
    "           .from_tensor_slices((sg_centers, sg_contexts))\n",
    "           .shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "print(\"CBOW examples:\", cbow_contexts.shape,\n",
    "      \"Skip‑Gram examples:\", sg_centers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8673f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CBOW\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CBOW\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">53,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">533</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">53,833</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │          \u001b[38;5;34m53,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m533\u001b[0m)                 │          \u001b[38;5;34m53,833\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,133</span> (418.49 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m107,133\u001b[0m (418.49 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,133</span> (418.49 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m107,133\u001b[0m (418.49 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SkipGram\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SkipGram\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">53,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">533</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">53,833</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m)                      │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m53,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m533\u001b[0m)                 │          \u001b[38;5;34m53,833\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,133</span> (418.49 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m107,133\u001b[0m (418.49 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,133</span> (418.49 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m107,133\u001b[0m (418.49 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cbow_inputs = Input(shape=(2*window_size,), dtype='int32')\n",
    "emb_layer_c = layers.Embedding(input_dim=V, output_dim=vector_dim)\n",
    "x = emb_layer_c(cbow_inputs)                     \n",
    "x = layers.GlobalAveragePooling1D()(x)           \n",
    "cbow_outputs = layers.Dense(V)(x)                \n",
    "cbow_model = Model(cbow_inputs, cbow_outputs, name=\"CBOW\")\n",
    "cbow_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")\n",
    "\n",
    "sg_inputs = Input(shape=(), dtype='int32')\n",
    "emb_layer_s = layers.Embedding(input_dim=V, output_dim=vector_dim)\n",
    "y = emb_layer_s(sg_inputs)                       \n",
    "sg_outputs = layers.Dense(V)(y)                   \n",
    "sg_model = Model(sg_inputs, sg_outputs, name=\"SkipGram\")\n",
    "sg_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")\n",
    "\n",
    "cbow_model.summary()\n",
    "sg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a2b1ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1730\n",
      "Epoch 2/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1613 \n",
      "Epoch 3/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1106 \n",
      "Epoch 4/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1164 \n",
      "Epoch 5/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2561 \n"
     ]
    }
   ],
   "source": [
    "history_cbow = cbow_model.fit(cbow_ds, epochs=epochs)\n",
    "embeddings_cbow = emb_layer_c.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5adfde3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4941\n",
      "Epoch 2/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4292\n",
      "Epoch 3/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3677\n",
      "Epoch 4/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3901\n",
      "Epoch 5/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4003\n"
     ]
    }
   ],
   "source": [
    "history_sg = sg_model.fit(sg_ds, epochs=epochs)\n",
    "embeddings_sg = emb_layer_s.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e55835b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CBOW Training Loss:    4.2168\n",
      "Final Skip‑Gram Training Loss: 6.3944\n"
     ]
    }
   ],
   "source": [
    "final_cbow_loss = history_cbow.history['loss'][-1]\n",
    "final_sg_loss   = history_sg.history['loss'][-1]\n",
    "print(f\"Final CBOW Training Loss:    {final_cbow_loss:.4f}\")\n",
    "print(f\"Final Skip‑Gram Training Loss: {final_sg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37baeb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\tCBOW Neighbors\t\t\t\t\t\tSkipGram Neighbors\n",
      "refund\t['inaugural', 'through', 'tax', 'warranty', 'accepts']\t\t['four', 'named', 'defective', 'how', 'tells']\n",
      "public\t['exact', 'rerelease', 'caps', 'assassination', 'tax']\t\t['days', 'cannot', 'displayed', 'works', 'plain']\n",
      "small\t['testing', 'asterisk', 'for', 'conversion', 'ground']\t\t['contain', 'inaccurate', 'used', 'which', 'distribution']\n",
      "medium\t['years', 'thanks', 'dead', 'score', 'long']\t\t['apply', 'wish', 'you', 'disk', 'donations']\n",
      "college\t['proposition', 'you', 'modify', 'birth', 'below']\t\t['near', 'conversion', 'measure', 'named', 'deleted']\n"
     ]
    }
   ],
   "source": [
    "def nearest_safe(word, embeddings, idx2word, word2idx, topn=5):\n",
    "    if word not in word2idx:\n",
    "        return []\n",
    "    idx = word2idx[word]\n",
    "    sims = cosine_similarity([embeddings[idx]], embeddings)[0]\n",
    "    nn = np.argsort(-sims)[1:1+topn]\n",
    "    return [idx2word[i] for i in nn]\n",
    "\n",
    "probe = [\"refund\",\"public\",\"small\",\"medium\",\"college\"]\n",
    "print(\"Word\\tCBOW Neighbors\\t\\t\\t\\t\\t\\tSkipGram Neighbors\")\n",
    "for w in probe:\n",
    "    print(f\"{w}\\t{nearest_safe(w, embeddings_cbow, idx2word, word2idx)}\\t\\t{nearest_safe(w, embeddings_sg, idx2word, word2idx)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "862dde28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analogy\t\t\tCBOW\t\t\tSkipGram\n",
      "case-college+project\tproprietary\t\toriginal\n",
      "print-legal+public\ta\t\tcontinent\n",
      "refund-domain+medium\tdedicate\t\thold\n"
     ]
    }
   ],
   "source": [
    "def analogy(a, b, c, embeddings, idx2word, word2idx):\n",
    "    if any(x not in word2idx for x in (a,b,c)): return None\n",
    "    va, vb, vc = embeddings[word2idx[a]], embeddings[word2idx[b]], embeddings[word2idx[c]]\n",
    "    target = va - vb + vc\n",
    "    sims = cosine_similarity([target], embeddings)[0]\n",
    "    for idx in np.argsort(-sims):\n",
    "        w = idx2word[idx]\n",
    "        if w not in {a,b,c}: return w\n",
    "    return None\n",
    "\n",
    "tests = [\n",
    "    (\"case\",\"college\",\"project\"),\n",
    "    (\"print\",\"legal\",\"public\"),\n",
    "    (\"refund\",\"domain\",\"medium\"),\n",
    "]\n",
    "print(\"\\nAnalogy\\t\\t\\tCBOW\\t\\t\\tSkipGram\")\n",
    "for a,b,c in tests:\n",
    "    print(f\"{a}-{b}+{c}\\t{analogy(a,b,c,embeddings_cbow,idx2word,word2idx)}\\t\\t{analogy(a,b,c,embeddings_sg,idx2word,word2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a72d4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pairwise Cosine Similarities:\n",
      "public-domain: CBOW=0.263, SkipGram=0.222\n",
      "legal-refund: CBOW=0.204, SkipGram=0.050\n",
      "nation-new: CBOW=0.088, SkipGram=0.020\n"
     ]
    }
   ],
   "source": [
    "pairs = [(\"public\",\"domain\"), (\"legal\",\"refund\"), (\"nation\",\"new\")]\n",
    "print(\"\\nPairwise Cosine Similarities:\")\n",
    "for a,b in pairs:\n",
    "    if a in word2idx and b in word2idx:\n",
    "        sim_cb = cosine_similarity([embeddings_cbow[word2idx[a]]],\n",
    "                                   [embeddings_cbow[word2idx[b]]])[0,0]\n",
    "        sim_sg = cosine_similarity([embeddings_sg[word2idx[a]]],\n",
    "                                   [embeddings_sg[word2idx[b]]])[0,0]\n",
    "        print(f\"{a}-{b}: CBOW={sim_cb:.3f}, SkipGram={sim_sg:.3f}\")\n",
    "    else:\n",
    "        print(f\"{a}-{b}: word(s) not in vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f200af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
